{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm # progress tracker\n",
    "import pyranges as pr # parsing gff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Parse raw junction data from regtools output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJunctionFiles(directory_path, file_pattern=\"*.reverse.output.junc\", file_count=10):\n",
    "\n",
    "    all_data = []\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "\n",
    "    # slicing data set (set file_count to None to include all data)\n",
    "    if file_count is not None and file_count > 0:\n",
    "        file_paths_to_process = file_paths[:file_count]\n",
    "        print(f\"Found {len(file_paths)} files. Processing the first {len(file_paths_to_process)} files.\")\n",
    "    else:\n",
    "        file_paths_to_process = file_paths\n",
    "        print(f\"Found {len(file_paths_to_process)} files to process.\")\n",
    "\n",
    "    # pre-modification columns \n",
    "    regtools_column_names = [\n",
    "        'chrom', 'start_anchor', 'end_anchor', 'name', 'score', 'strand',\n",
    "        'thick_start_orig', 'thick_end_orig', 'item_rgb_orig',\n",
    "        'block_count_orig', 'block_sizes_orig', 'block_starts_orig'\n",
    "    ]\n",
    "    \n",
    "    for file_path in tqdm(file_paths_to_process):\n",
    "        try:\n",
    "            sample_id = os.path.basename(file_path).split('.')[0]\n",
    "            df = pd.read_csv(\n",
    "                file_path, sep='\\t', header=None, names=regtools_column_names,\n",
    "                dtype={'chrom': str, 'block_sizes_orig': str, 'block_starts_orig': str}\n",
    "            )\n",
    "            if df.empty:\n",
    "                print(f\"File is empty or failed to load: {file_path}\")\n",
    "                continue\n",
    "            df['sample_id_source'] = sample_id\n",
    "            all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No data was read from any file.\")\n",
    "        return None\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nSuccessfully combined raw data from {len(all_data)} files into a df with {len(combined_df)} rows.\")\n",
    "    \n",
    "    # type conversion for  numeric columns from regtools\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        if col in combined_df.columns:\n",
    "            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "    \n",
    "    # drop rows if info is missing\n",
    "    combined_df.dropna(subset=['start_anchor', 'end_anchor', 'score', 'block_sizes_orig'], inplace=True)\n",
    "    # ensure int types\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "         combined_df[col] = combined_df[col].astype(int)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transform raw regtools df into BED12 df where each entry is an intron/junction. Junction coords recalculated, taking into account blockSize. Recalculated block size to represent length of junction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformJunctionData(raw_df):\n",
    "    if raw_df.empty:\n",
    "        print(\"Raw DataFrame is empty.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # CHROMOSOME FILTERING\n",
    "    original_row_count = len(raw_df)\n",
    "    \n",
    "    # allowed chromosomes\n",
    "    allowed_chrom_numbers = [str(i) for i in range(1, 23)]\n",
    "    allowed_sex_chroms_upper = ['X', 'Y'] \n",
    "    \n",
    "    allowed_chromosomes = set()\n",
    "    for num_chrom in allowed_chrom_numbers:\n",
    "        allowed_chromosomes.add(num_chrom)\n",
    "        allowed_chromosomes.add(f\"chr{num_chrom}\")\n",
    "    for sex_chrom in allowed_sex_chroms_upper:\n",
    "        allowed_chromosomes.add(sex_chrom)\n",
    "        allowed_chromosomes.add(sex_chrom.lower())\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom}\")\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom.lower()}\")\n",
    "    \n",
    "    raw_df_filtered = raw_df[raw_df['chrom'].isin(allowed_chromosomes)].copy()\n",
    "    \n",
    "    filtered_row_count = len(raw_df_filtered)\n",
    "    print(f\"Removed {original_row_count - filtered_row_count} rows with non-standard chromosomes.\")\n",
    "\n",
    "    # JUNCTION COORD CORRECTION\n",
    "    # initialize lists for each column\n",
    "    chrom_list = []\n",
    "    chromStart_list = []\n",
    "    chromEnd_list = []\n",
    "    name_list = []\n",
    "    score_list = []\n",
    "    strand_list = []\n",
    "    thickStart_list = []\n",
    "    thickEnd_list = []\n",
    "    itemRgb_list = []\n",
    "    blockCount_list = []\n",
    "    blockSizes_list = []\n",
    "    blockStarts_list = []\n",
    "    sample_id_source_list = []\n",
    "    \n",
    "    skipped_rows = 0\n",
    "\n",
    "    # iterate over the filtered df (set to 1000 rows)\n",
    "    for i, (index, row) in enumerate(tqdm(raw_df_filtered.iterrows(), total=1000)):\n",
    "        if i >= 1000:\n",
    "            break\n",
    "        try:\n",
    "            regtools_start = row['start_anchor']\n",
    "            regtools_end = row['end_anchor']\n",
    "            regtools_block_sizes_str = row['block_sizes_orig']\n",
    "\n",
    "            parsed_block_sizes = [int(s) for s in regtools_block_sizes_str.strip(',').split(',')]\n",
    "            if len(parsed_block_sizes) < 2:\n",
    "                skipped_rows += 1\n",
    "                continue\n",
    "            \n",
    "            overhang_left = parsed_block_sizes[0]\n",
    "            overhang_right = parsed_block_sizes[1]\n",
    "\n",
    "            junc_start = regtools_start + overhang_left\n",
    "            junc_end = regtools_end - overhang_right\n",
    "\n",
    "            if junc_start >= junc_end: \n",
    "                skipped_rows += 1\n",
    "                continue\n",
    "\n",
    "            junc_length = junc_end - junc_start\n",
    "\n",
    "            # add values to respective lists\n",
    "            chrom_list.append(row['chrom'])\n",
    "            chromStart_list.append(junc_start)\n",
    "            chromEnd_list.append(junc_end)\n",
    "            name_list.append(row['name'])\n",
    "            score_list.append(row['score'])\n",
    "            strand_list.append(row['strand'])\n",
    "            thickStart_list.append(junc_start)\n",
    "            thickEnd_list.append(junc_end)\n",
    "            itemRgb_list.append(row.get('item_rgb_orig', '0'))\n",
    "            blockCount_list.append(1)\n",
    "            blockSizes_list.append(str(junc_length))\n",
    "            blockStarts_list.append(\"0\")\n",
    "            sample_id_source_list.append(row['sample_id_source'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "    \n",
    "    if skipped_rows > 0:\n",
    "        print(f\"Skipped {skipped_rows} rows.\")\n",
    "\n",
    "    # create df from dictionary of lists\n",
    "    transformed_df = pd.DataFrame({\n",
    "        'chrom': chrom_list,\n",
    "        'chromStart': chromStart_list,\n",
    "        'chromEnd': chromEnd_list,\n",
    "        'name': name_list,\n",
    "        'score': score_list,\n",
    "        'strand': strand_list,\n",
    "        'thickStart': thickStart_list,\n",
    "        'thickEnd': thickEnd_list,\n",
    "        'itemRgb': itemRgb_list,\n",
    "        'blockCount': blockCount_list,\n",
    "        'blockSizes': blockSizes_list,\n",
    "        'blockStarts': blockStarts_list,\n",
    "        'sample_id_source': sample_id_source_list\n",
    "    })\n",
    "    \n",
    "    print(f\"Transformed {len(transformed_df)} junction records.\")\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1876 files. Processing the first 10 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully combined raw data from 10 files into a df with 3102409 rows.\n",
      "Removed 5253 rows with non-standard chromosomes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 429.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1000 records.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>chromStart</th>\n",
       "      <th>chromEnd</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>thickStart</th>\n",
       "      <th>thickEnd</th>\n",
       "      <th>itemRgb</th>\n",
       "      <th>blockCount</th>\n",
       "      <th>blockSizes</th>\n",
       "      <th>blockStarts</th>\n",
       "      <th>sample_id_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>14829</td>\n",
       "      <td>14969</td>\n",
       "      <td>JUNC00000001</td>\n",
       "      <td>101</td>\n",
       "      <td>-</td>\n",
       "      <td>14829</td>\n",
       "      <td>14969</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>14829</td>\n",
       "      <td>14962</td>\n",
       "      <td>JUNC00000003</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>14829</td>\n",
       "      <td>14962</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>14829</td>\n",
       "      <td>185483</td>\n",
       "      <td>JUNC00000002</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>14829</td>\n",
       "      <td>185483</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>170654</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>15038</td>\n",
       "      <td>15795</td>\n",
       "      <td>JUNC00000004</td>\n",
       "      <td>30</td>\n",
       "      <td>-</td>\n",
       "      <td>15038</td>\n",
       "      <td>15795</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>15038</td>\n",
       "      <td>15310</td>\n",
       "      <td>JUNC00000005</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>15038</td>\n",
       "      <td>15310</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1670151</td>\n",
       "      <td>1738320</td>\n",
       "      <td>JUNC00001016</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>1670151</td>\n",
       "      <td>1738320</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>68169</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1670151</td>\n",
       "      <td>1671508</td>\n",
       "      <td>JUNC00001014</td>\n",
       "      <td>36</td>\n",
       "      <td>-</td>\n",
       "      <td>1670151</td>\n",
       "      <td>1671508</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>1357</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1671629</td>\n",
       "      <td>1675462</td>\n",
       "      <td>JUNC00001017</td>\n",
       "      <td>58</td>\n",
       "      <td>-</td>\n",
       "      <td>1671629</td>\n",
       "      <td>1675462</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1675590</td>\n",
       "      <td>1676063</td>\n",
       "      <td>JUNC00001018</td>\n",
       "      <td>63</td>\n",
       "      <td>-</td>\n",
       "      <td>1675590</td>\n",
       "      <td>1676063</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>473</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1676199</td>\n",
       "      <td>1676377</td>\n",
       "      <td>JUNC00001019</td>\n",
       "      <td>43</td>\n",
       "      <td>-</td>\n",
       "      <td>1676199</td>\n",
       "      <td>1676377</td>\n",
       "      <td>255,0,0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>CGND-HRA-02241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chrom  chromStart  chromEnd          name  score strand  thickStart  \\\n",
       "0    chr1       14829     14969  JUNC00000001    101      -       14829   \n",
       "1    chr1       14829     14962  JUNC00000003      1      -       14829   \n",
       "2    chr1       14829    185483  JUNC00000002      1      -       14829   \n",
       "3    chr1       15038     15795  JUNC00000004     30      -       15038   \n",
       "4    chr1       15038     15310  JUNC00000005      2      -       15038   \n",
       "..    ...         ...       ...           ...    ...    ...         ...   \n",
       "995  chr1     1670151   1738320  JUNC00001016      4      -     1670151   \n",
       "996  chr1     1670151   1671508  JUNC00001014     36      -     1670151   \n",
       "997  chr1     1671629   1675462  JUNC00001017     58      -     1671629   \n",
       "998  chr1     1675590   1676063  JUNC00001018     63      -     1675590   \n",
       "999  chr1     1676199   1676377  JUNC00001019     43      -     1676199   \n",
       "\n",
       "     thickEnd  itemRgb  blockCount blockSizes blockStarts sample_id_source  \n",
       "0       14969  255,0,0           1        140           0   CGND-HRA-02241  \n",
       "1       14962  255,0,0           1        133           0   CGND-HRA-02241  \n",
       "2      185483  255,0,0           1     170654           0   CGND-HRA-02241  \n",
       "3       15795  255,0,0           1        757           0   CGND-HRA-02241  \n",
       "4       15310  255,0,0           1        272           0   CGND-HRA-02241  \n",
       "..        ...      ...         ...        ...         ...              ...  \n",
       "995   1738320  255,0,0           1      68169           0   CGND-HRA-02241  \n",
       "996   1671508  255,0,0           1       1357           0   CGND-HRA-02241  \n",
       "997   1675462  255,0,0           1       3833           0   CGND-HRA-02241  \n",
       "998   1676063  255,0,0           1        473           0   CGND-HRA-02241  \n",
       "999   1676377  255,0,0           1        178           0   CGND-HRA-02241  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING: transforming parsed data\n",
    "transformJunctionData(parseJunctionFiles(\"/gpfs/commons/groups/knowles_lab/atokolyi/als/juncs/\",file_pattern=\"*.reverse.output.junc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Filter for junctions that are contained within exon sequences (obtain from gff file, parse using pyranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>+</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>+</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>-</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr3</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>+</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  |    Chromosome      Start      End  Strand    title\n",
       "  int64  |    object          int64    int64  object    object\n",
       "-------  ---  ------------  -------  -------  --------  --------\n",
       "      0  |    chr1                5       10  +         a\n",
       "      1  |    chr1               20       28  +         b\n",
       "      2  |    chr1               80       95  -         c\n",
       "      3  |    chr3               10       38  +         d\n",
       "PyRanges with 4 rows, 5 columns, and 1 index columns.\n",
       "Contains 2 chromosomes and 2 strands."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "cds = gff[gff['Feature']==\"CDS\"] #only CDS (protein-coding exons)\n",
    "\n",
    "gr = pr.PyRanges({'Chromosome': ['chr1', 'chr1', 'chr1', 'chr3'],\n",
    "                  'Start': [5, 20, 80, 10],\n",
    "                  'End': [10, 28, 95, 38],\n",
    "                  'Strand': ['+', '+', '-', '+'],\n",
    "                  'title': ['a', 'b', 'c', 'd']}) # Can use junction IDs here i.e. chr:start:end:strand\n",
    "# Use the pyranges overlap function to find which of these junctions are wholly contained within CDS\n",
    "\n",
    "def findExitrons(junction_df, gff_file_path):\n",
    "\n",
    "    print(f\"\\nLoading GFF3 file: {gff_file_path} for CDS filtering...\")\n",
    "    try:\n",
    "        gff_pr = pr.read_gff3(gff_file_path, duplicate_attr=True) # duplicate_attr=True might be needed for some GFFs\n",
    "        cds_pr = gff_pr[gff_pr.Feature == \"CDS\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or processing GFF3 file: {e}\")\n",
    "        return junction_df # Return original on error\n",
    "\n",
    "    if cds_pr.empty:\n",
    "        print(\"No CDS features found in GFF3 file. Returning unfiltered junctions.\")\n",
    "        return junction_df\n",
    "\n",
    "    print(f\"Found {len(cds_pr)} CDS features.\")\n",
    "\n",
    "    # Convert junction DataFrame to PyRanges object\n",
    "    # PyRanges uses 'Chromosome', 'Start', 'End', 'Strand' by default\n",
    "    # Our junction_df uses 'chrom', 'chromStart', 'chromEnd', 'strand'\n",
    "    # Keep all other columns from junction_df\n",
    "    \n",
    "    # Create a mapping for column names to PyRanges standard names\n",
    "    column_map = {\n",
    "        'chrom': 'Chromosome',\n",
    "        'chromStart': 'Start',\n",
    "        'chromEnd': 'End',\n",
    "        'strand': 'Strand'\n",
    "    }\n",
    "    junctions_pr_df_renamed = junction_df.rename(columns=column_map)\n",
    "    junctions_pr = pr.PyRanges(junctions_pr_df_renamed)\n",
    "    \n",
    "    print(f\"Converted {len(junctions_pr)} junctions to PyRanges object for CDS filtering.\")\n",
    "\n",
    "    # Filter junctions that are subsets of (contained within) CDS features\n",
    "    # A.issubset(B) returns a new PyRanges object with intervals from A that are subsets of intervals in B\n",
    "    contained_junctions_pr = junctions_pr.issubset(cds_pr)\n",
    "    \n",
    "    original_junction_count = len(junction_df)\n",
    "    filtered_junction_count = len(contained_junctions_pr)\n",
    "    print(f\"CDS containment filtering: Kept {filtered_junction_count} junctions out of {original_junction_count} (removed {original_junction_count - filtered_junction_count} junctions not contained within CDS).\")\n",
    "\n",
    "    if contained_junctions_pr.empty:\n",
    "        print(\"No junctions were found to be contained within CDS regions.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Convert back to pandas DataFrame, reverting column names for consistency\n",
    "    # The PyRanges df attribute will have the standard PyRanges column names\n",
    "    filtered_junction_df_std_names = contained_junctions_pr.df\n",
    "    \n",
    "    # Revert column names to original for consistency with other functions\n",
    "    reverse_column_map = {v: k for k, v in column_map.items()}\n",
    "    filtered_junction_df_original_names = filtered_junction_df_std_names.rename(columns=reverse_column_map)\n",
    "    \n",
    "    return filtered_junction_df_original_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Summarize junction info as list of unique junctions and their counts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
