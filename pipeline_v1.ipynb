{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Pipeline for Detecting Exitrons (Exonic Introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm # progress tracker\n",
    "import pyranges as pr # parsing gff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse Regtools Data \n",
    "- Parse raw junction data from regtools output files\n",
    "\n",
    "- Processes 1 file at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJunctionFile(file_path):\n",
    "    # column names for RegTools junction files\n",
    "    regtools_column_names = [\n",
    "        'chrom', 'start_anchor', 'end_anchor', 'name', 'score', 'strand',\n",
    "        'thick_start_orig', 'thick_end_orig', 'item_rgb_orig',\n",
    "        'block_count_orig', 'block_sizes_orig', 'block_starts_orig'\n",
    "    ]\n",
    "    \n",
    "    # extract sample ID from the filename\n",
    "    sample_id = os.path.basename(file_path).split('.')[0]\n",
    "    \n",
    "    # read the file into a pandas DataFrame\n",
    "    df = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None, names=regtools_column_names,\n",
    "        dtype={'chrom': str, 'block_sizes_orig': str, 'block_starts_orig': str}\n",
    "    )\n",
    "        \n",
    "    df['sample_id_source'] = sample_id\n",
    "\n",
    "    # convert relevant columns to numeric types, coercing errors\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # drop rows if info is missing\n",
    "    df.dropna(subset=['start_anchor', 'end_anchor', 'score', 'block_sizes_orig'], inplace=True)\n",
    "    \n",
    "    # ensure int types\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Junction Data\n",
    "- Recalculates junction coordinates, following Regtools documentation to take into account blockSize\n",
    "\n",
    "- Recalculates block size to represent length of junction\n",
    "\n",
    "- Outputs junction info in BED12 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformJunctionData(raw_df):\n",
    "    \n",
    "    # CHROMOSOME FILTERING\n",
    "    original_row_count = len(raw_df)\n",
    "    \n",
    "    # allowed chromosomes\n",
    "    allowed_chrom_numbers = [str(i) for i in range(1, 23)]\n",
    "    allowed_sex_chroms_upper = ['X', 'Y'] \n",
    "    allowed_chromosomes = set()\n",
    "    for num_chrom in allowed_chrom_numbers:\n",
    "        allowed_chromosomes.add(num_chrom)\n",
    "        allowed_chromosomes.add(f\"chr{num_chrom}\")\n",
    "    for sex_chrom in allowed_sex_chroms_upper:\n",
    "        allowed_chromosomes.add(sex_chrom)\n",
    "        allowed_chromosomes.add(sex_chrom.lower())\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom}\")\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom.lower()}\")\n",
    "    \n",
    "    raw_df_filtered = raw_df[raw_df['chrom'].isin(allowed_chromosomes)].copy()\n",
    "    filtered_row_count = len(raw_df_filtered)\n",
    "    print(f\"Removed {original_row_count - filtered_row_count} rows with non-standard chromosomes.\")\n",
    "\n",
    "\n",
    "    # JUNCTION COORD CORRECTION\n",
    "    # filter rows for valid blocks\n",
    "    parsed_blocks_list = raw_df_filtered['block_sizes_orig'].str.strip(',').str.split(',')\n",
    "    has_sufficient_blocks = parsed_blocks_list.str.len() >= 2\n",
    "    raw_df_filtered = raw_df_filtered[has_sufficient_blocks].copy()\n",
    "    parsed_blocks_list = parsed_blocks_list[has_sufficient_blocks]\n",
    "    \n",
    "    # recalculating junction coordinates\n",
    "    raw_df_filtered.loc[:, 'overhang_left'] = parsed_blocks_list.str[0].astype(int)\n",
    "    raw_df_filtered.loc[:, 'overhang_right'] = parsed_blocks_list.str[1].astype(int)\n",
    "\n",
    "    junc_start = raw_df_filtered['start_anchor'] + raw_df_filtered['overhang_left']\n",
    "    junc_end = raw_df_filtered['end_anchor'] - raw_df_filtered['overhang_right']\n",
    "\n",
    "    # filter out invalid junctions\n",
    "    valid_junction = junc_start < junc_end\n",
    "    raw_df_filtered = raw_df_filtered[valid_junction].copy()\n",
    "    junc_start = junc_start[valid_junction]\n",
    "    junc_end = junc_end[valid_junction]\n",
    "\n",
    "\n",
    "    junc_length = junc_end - junc_start\n",
    "\n",
    "    # create df\n",
    "    transformed_df = pd.DataFrame()\n",
    "    transformed_df['chrom'] = raw_df_filtered['chrom']\n",
    "    transformed_df['chromStart'] = junc_start\n",
    "    transformed_df['chromEnd'] = junc_end\n",
    "    transformed_df['name'] = raw_df_filtered['name']\n",
    "    transformed_df['score'] = raw_df_filtered['score']\n",
    "    transformed_df['strand'] = raw_df_filtered['strand']\n",
    "    transformed_df['thickStart'] = junc_start\n",
    "    transformed_df['thickEnd'] = junc_end\n",
    "    transformed_df['itemRgb'] = raw_df_filtered['item_rgb_orig']\n",
    "    transformed_df['blockCount'] = 1\n",
    "    transformed_df['blockSizes'] = junc_length.astype(str)\n",
    "    transformed_df['blockStarts'] = \"0\"\n",
    "    transformed_df['sample_id_source'] = raw_df_filtered['sample_id_source']\n",
    "\n",
    "    print(f\"Transformed {len(transformed_df)} junction records.\")\n",
    "    \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Exitrons Within Junction Data\n",
    "- Converts transformed junction data (transformed_df) and exon data (from gff3 file) into PyRanges objects with labels Chromosome, Start, End, Strand, and Title (a unique junction id formed by chrom:start:end:strand)\n",
    "\n",
    "- Finds junctions that overlap with CDS regions using PyRanges method .overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 903356 CDS regions.\n"
     ]
    }
   ],
   "source": [
    "# convert CDS data to PyRanges object\n",
    "gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "cds = gff[gff.Feature == \"CDS\"]\n",
    "print(f\"Found {len(cds)} CDS regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findExitrons(transformed_df):\n",
    "    # generate a unique ID for each junction (chrom:start:end:strand\n",
    "    unique_id = transformed_df['chrom'].astype(str) + ':' + \\\n",
    "                transformed_df['chromStart'].astype(str) + ':' + \\\n",
    "                transformed_df['chromEnd'].astype(str) + ':' + \\\n",
    "                transformed_df['strand'].astype(str)\n",
    "\n",
    "    # convert junction data to PyRanges object\n",
    "    junction_pr = pr.PyRanges({'Chromosome': transformed_df['chrom'],\n",
    "                    'Start': transformed_df['chromStart'],\n",
    "                    'End': transformed_df['chromEnd'],\n",
    "                    'Strand': transformed_df['strand'],\n",
    "                    'title': unique_id,\n",
    "                    'reads': transformed_df['score'],\n",
    "                    'sourceID': transformed_df['sample_id_source']}) \n",
    "\n",
    "    # find overlapping junctions\n",
    "    contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
    "    print(f\"Found {len(contained_junctions)} junctions contained within CDS regions.\")\n",
    "            \n",
    "    return contained_junctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile All Exitron Info\n",
    "- Iterates through each person's file, finding all exitron data then concatenating to a final matrix\n",
    "\n",
    "- Includes person ID (file name) and junction scores (total reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileExitronData(directory_path, file_pattern=\"*.bam.junc\"):\n",
    "\n",
    "    all_exitron_info = []\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "    print(f\"Found {len(file_paths)} files to process.\")\n",
    "\n",
    "    # testing first 5 out of 100\n",
    "    files_to_process = file_paths[:5]\n",
    "    print(f\"Processing the first {len(files_to_process)} files.\")\n",
    "\n",
    "    for file_path in tqdm(files_to_process):\n",
    "        print(\"Parsing new file...\")\n",
    "        file_name_only = os.path.basename(file_path)\n",
    "        try:\n",
    "            # 1.\n",
    "            parsed_data = parseJunctionFile(file_path)\n",
    "            # 2.\n",
    "            transformed_df = transformJunctionData(parsed_data)\n",
    "            # 3.\n",
    "            gr_file = findExitrons(transformed_df)\n",
    "            #4.\n",
    "            all_exitron_info.append(gr_file)\n",
    "\n",
    "        # skip to the next file if an error occurs\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing file {file_name_only}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue \n",
    "\n",
    "    # concatenate all individual data into matrix \n",
    "    final_gr = pr.concat(all_exitron_info)\n",
    "    print(f\"\\nSuccessfully compiled exitron data from {len(all_exitron_info)} files.\")\n",
    "    return final_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 files to process.\n",
      "Processing the first 5 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing new file...\n",
      "Removed 686 rows with non-standard chromosomes.\n",
      "Transformed 277524 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1803036/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 20%|██        | 1/5 [00:05<00:21,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8193 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1009 rows with non-standard chromosomes.\n",
      "Transformed 301814 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1803036/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 40%|████      | 2/5 [00:11<00:16,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9622 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 671 rows with non-standard chromosomes.\n",
      "Transformed 270306 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1803036/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 60%|██████    | 3/5 [00:16<00:10,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10160 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1380 rows with non-standard chromosomes.\n",
      "Transformed 319404 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1803036/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 80%|████████  | 4/5 [00:21<00:05,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12373 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1098 rows with non-standard chromosomes.\n",
      "Transformed 290857 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1803036/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      "100%|██████████| 5/5 [00:27<00:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7620 junctions contained within CDS regions.\n",
      "\n",
      "Successfully compiled exitron data from 5 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>title</th>\n",
       "      <th>reads</th>\n",
       "      <th>sourceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>chr1</td>\n",
       "      <td>943808</td>\n",
       "      <td>943907</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:943808:943907:+</td>\n",
       "      <td>34</td>\n",
       "      <td>CGND-HRA-00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>chr1</td>\n",
       "      <td>999787</td>\n",
       "      <td>999865</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:999787:999865:-</td>\n",
       "      <td>3</td>\n",
       "      <td>CGND-HRA-00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1084016</td>\n",
       "      <td>1084352</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1084016:1084352:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1084016</td>\n",
       "      <td>1084352</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1084016:1084352:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1084086</td>\n",
       "      <td>1084352</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1084086:1084352:-</td>\n",
       "      <td>2</td>\n",
       "      <td>CGND-HRA-00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291485</th>\n",
       "      <td>chrY</td>\n",
       "      <td>13335800</td>\n",
       "      <td>13335891</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:13335800:13335891:-</td>\n",
       "      <td>4</td>\n",
       "      <td>CGND-HRA-00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291485</th>\n",
       "      <td>chrY</td>\n",
       "      <td>13335800</td>\n",
       "      <td>13335891</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:13335800:13335891:-</td>\n",
       "      <td>4</td>\n",
       "      <td>CGND-HRA-00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291485</th>\n",
       "      <td>chrY</td>\n",
       "      <td>13335800</td>\n",
       "      <td>13335891</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:13335800:13335891:-</td>\n",
       "      <td>4</td>\n",
       "      <td>CGND-HRA-00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291485</th>\n",
       "      <td>chrY</td>\n",
       "      <td>13335800</td>\n",
       "      <td>13335891</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:13335800:13335891:-</td>\n",
       "      <td>4</td>\n",
       "      <td>CGND-HRA-00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291485</th>\n",
       "      <td>chrY</td>\n",
       "      <td>13335800</td>\n",
       "      <td>13335891</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:13335800:13335891:-</td>\n",
       "      <td>4</td>\n",
       "      <td>CGND-HRA-00038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47968 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "index    |    Chromosome    Start     End       Strand    ...\n",
       "int64    |    object        int64     int64     object    ...\n",
       "-------  ---  ------------  --------  --------  --------  -----\n",
       "919      |    chr1          943808    943907    +         ...\n",
       "955      |    chr1          999787    999865    -         ...\n",
       "1009     |    chr1          1084016   1084352   -         ...\n",
       "1009     |    chr1          1084016   1084352   -         ...\n",
       "...      |    ...           ...       ...       ...       ...\n",
       "291485   |    chrY          13335800  13335891  -         ...\n",
       "291485   |    chrY          13335800  13335891  -         ...\n",
       "291485   |    chrY          13335800  13335891  -         ...\n",
       "291485   |    chrY          13335800  13335891  -         ...\n",
       "PyRanges with 47968 rows, 7 columns, and 1 index columns (with 33788 index duplicates). (3 columns not shown: \"title\", \"reads\", \"sourceID\").\n",
       "Contains 24 chromosomes and 3 strands (including non-genomic strands: ?)."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compileExitronData(\"/gpfs/commons/groups/knowles_lab/atokolyi/als/juncs_min6bp/\",file_pattern=\"*.bam.junc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Summarize Exitron Info \n",
    "- Lists all unique exitrons and their counts\n",
    "\n",
    "- Identifies which exitrons are already annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exitron Normalization\n",
    "- Divides exitron score by the reads of surrounding exons to find proportion of time that the exitron gets expressed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
