{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm # progress tracker\n",
    "import pyranges as pr # parsing gff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse Regtools Data \n",
    "- Parse raw junction data from regtools output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJunctionFiles(directory_path, file_pattern=\"*.reverse.output.junc\", file_count=1):\n",
    "\n",
    "    all_data = []\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "\n",
    "    # slicing data set (set file_count to None to include all data)\n",
    "    if file_count is not None and file_count > 0:\n",
    "        file_paths_to_process = file_paths[:file_count]\n",
    "        print(f\"Found {len(file_paths)} files. Processing the first {len(file_paths_to_process)} files.\")\n",
    "    else:\n",
    "        file_paths_to_process = file_paths\n",
    "        print(f\"Found {len(file_paths_to_process)} files to process.\")\n",
    "\n",
    "    # pre-modification columns \n",
    "    regtools_column_names = [\n",
    "        'chrom', 'start_anchor', 'end_anchor', 'name', 'score', 'strand',\n",
    "        'thick_start_orig', 'thick_end_orig', 'item_rgb_orig',\n",
    "        'block_count_orig', 'block_sizes_orig', 'block_starts_orig'\n",
    "    ]\n",
    "    \n",
    "    for file_path in tqdm(file_paths_to_process):\n",
    "        try:\n",
    "            sample_id = os.path.basename(file_path).split('.')[0]\n",
    "            df = pd.read_csv(\n",
    "                file_path, sep='\\t', header=None, names=regtools_column_names,\n",
    "                dtype={'chrom': str, 'block_sizes_orig': str, 'block_starts_orig': str}\n",
    "            )\n",
    "            if df.empty:\n",
    "                print(f\"File is empty or failed to load: {file_path}\")\n",
    "                continue\n",
    "            df['sample_id_source'] = sample_id\n",
    "            all_data.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No data was read from any file.\")\n",
    "        return None\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nSuccessfully combined raw data from {len(all_data)} files into a df with {len(combined_df)} rows.\")\n",
    "    \n",
    "    # type conversion for  numeric columns from regtools\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        if col in combined_df.columns:\n",
    "            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "    \n",
    "    # drop rows if info is missing\n",
    "    combined_df.dropna(subset=['start_anchor', 'end_anchor', 'score', 'block_sizes_orig'], inplace=True)\n",
    "    # ensure int types\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "         combined_df[col] = combined_df[col].astype(int)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Junction Data\n",
    "- Recalculates junction coordinates, following Regtools documentation to take into account blockSize\n",
    "- Recalculates block size to represent length of junction\n",
    "- Outputs junctino info in BED12 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformJunctionData(raw_df):\n",
    "    if raw_df.empty:\n",
    "        print(\"Raw DataFrame is empty.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # CHROMOSOME FILTERING\n",
    "    original_row_count = len(raw_df)\n",
    "    \n",
    "    # allowed chromosomes\n",
    "    allowed_chrom_numbers = [str(i) for i in range(1, 23)]\n",
    "    allowed_sex_chroms_upper = ['X', 'Y'] \n",
    "    \n",
    "    allowed_chromosomes = set()\n",
    "    for num_chrom in allowed_chrom_numbers:\n",
    "        allowed_chromosomes.add(num_chrom)\n",
    "        allowed_chromosomes.add(f\"chr{num_chrom}\")\n",
    "    for sex_chrom in allowed_sex_chroms_upper:\n",
    "        allowed_chromosomes.add(sex_chrom)\n",
    "        allowed_chromosomes.add(sex_chrom.lower())\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom}\")\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom.lower()}\")\n",
    "    \n",
    "    raw_df_filtered = raw_df[raw_df['chrom'].isin(allowed_chromosomes)].copy()\n",
    "    \n",
    "    filtered_row_count = len(raw_df_filtered)\n",
    "    print(f\"Removed {original_row_count - filtered_row_count} rows with non-standard chromosomes.\")\n",
    "\n",
    "    # JUNCTION COORD CORRECTION\n",
    "    # initialize lists for each column\n",
    "    chrom_list = []\n",
    "    chromStart_list = []\n",
    "    chromEnd_list = []\n",
    "    name_list = []\n",
    "    score_list = []\n",
    "    strand_list = []\n",
    "    thickStart_list = []\n",
    "    thickEnd_list = []\n",
    "    itemRgb_list = []\n",
    "    blockCount_list = []\n",
    "    blockSizes_list = []\n",
    "    blockStarts_list = []\n",
    "    sample_id_source_list = []\n",
    "\n",
    "    # iterate over the filtered df (set to 1000 rows)\n",
    "    for i, (index, row) in enumerate(tqdm(raw_df_filtered.iterrows(), total=100000000000000000)):\n",
    "        if i >= 100000000000000000:\n",
    "            break\n",
    "\n",
    "        regtools_start = row['start_anchor']\n",
    "        regtools_end = row['end_anchor']\n",
    "        regtools_block_sizes_str = row['block_sizes_orig']\n",
    "\n",
    "        parsed_block_sizes = [int(s) for s in regtools_block_sizes_str.strip(',').split(',')]\n",
    "        if len(parsed_block_sizes) < 2:\n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "        \n",
    "        overhang_left = parsed_block_sizes[0]\n",
    "        overhang_right = parsed_block_sizes[1]\n",
    "\n",
    "        junc_start = regtools_start + overhang_left\n",
    "        junc_end = regtools_end - overhang_right\n",
    "\n",
    "        if junc_start >= junc_end: \n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "\n",
    "        junc_length = junc_end - junc_start\n",
    "\n",
    "        # add values to respective lists\n",
    "        chrom_list.append(row['chrom'])\n",
    "        chromStart_list.append(junc_start)\n",
    "        chromEnd_list.append(junc_end)\n",
    "        name_list.append(row['name'])\n",
    "        score_list.append(row['score'])\n",
    "        strand_list.append(row['strand'])\n",
    "        thickStart_list.append(junc_start)\n",
    "        thickEnd_list.append(junc_end)\n",
    "        itemRgb_list.append(row.get('item_rgb_orig', '0'))\n",
    "        blockCount_list.append(1)\n",
    "        blockSizes_list.append(str(junc_length))\n",
    "        blockStarts_list.append(\"0\")\n",
    "        sample_id_source_list.append(row['sample_id_source'])\n",
    "\n",
    "    # create df from dictionary of lists\n",
    "    transformed_df = pd.DataFrame({\n",
    "        'chrom': chrom_list,\n",
    "        'chromStart': chromStart_list,\n",
    "        'chromEnd': chromEnd_list,\n",
    "        'name': name_list,\n",
    "        'score': score_list,\n",
    "        'strand': strand_list,\n",
    "        'thickStart': thickStart_list,\n",
    "        'thickEnd': thickEnd_list,\n",
    "        'itemRgb': itemRgb_list,\n",
    "        'blockCount': blockCount_list,\n",
    "        'blockSizes': blockSizes_list,\n",
    "        'blockStarts': blockStarts_list,\n",
    "        'sample_id_source': sample_id_source_list\n",
    "    })\n",
    "    \n",
    "    print(f\"Transformed {len(transformed_df)} junction records.\")\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files. Processing the first 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully combined raw data from 1 files into a df with 225494 rows.\n",
      "Removed 405 rows with non-standard chromosomes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3115.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1000 junction records.\n"
     ]
    }
   ],
   "source": [
    "transformed_df = transformJunctionData(parseJunctionFiles(\"/gpfs/commons/groups/knowles_lab/atokolyi/als/juncs_min6bp/\",file_pattern=\"*.bam.junc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert transformed junction data and exon data into PyRanges object including Chromosome, Start, End, Strand, and Title (a unique junction id). Find junctions that overlap with CDS regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findExitrons(junction_df):\n",
    "\n",
    "    # convert junction data to PyRanges object\n",
    "    unique_id = transformed_df['chrom'].astype(str) + ':' + \\\n",
    "                transformed_df['chromStart'].astype(str) + ':' + \\\n",
    "                transformed_df['chromEnd'].astype(str) + ':' + \\\n",
    "                transformed_df['strand'].astype(str)\n",
    "\n",
    "    junction_pr = pr.PyRanges({'Chromosome': transformed_df['chrom'],\n",
    "                    'Start': transformed_df['chromStart'],\n",
    "                    'End': transformed_df['chromEnd'],\n",
    "                    'Strand': transformed_df['strand'],\n",
    "                    'title': unique_id })\n",
    "    \n",
    "    # convert CDS data to PyRanges object\n",
    "    gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "    cds = gff[gff.Feature == \"CDS\"]\n",
    "\n",
    "    print(f\"Found {len(cds)} CDS features.\")\n",
    "\n",
    "    # overlapping junctions\n",
    "    contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
    "    print(f\"Found {len(contained_junctions)} junctions that are contained within CDS regions.\")\n",
    "            \n",
    "    return contained_junctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files. Processing the first 1 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully combined raw data from 1 files into a df with 225494 rows.\n",
      "Removed 405 rows with non-standard chromosomes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3086.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 1000 junction records.\n",
      "Found 903356 CDS features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1530779/3653940572.py:24: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 junctions that are contained within CDS regions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>chr1</td>\n",
       "      <td>999787</td>\n",
       "      <td>999865</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:999787:999865:-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1287596</td>\n",
       "      <td>1287672</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:1287596:1287672:+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1295826</td>\n",
       "      <td>1295889</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1295826:1295889:-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1295826</td>\n",
       "      <td>1295889</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1295826:1295889:-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2029762</td>\n",
       "      <td>2029982</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:2029762:2029982:+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2496880</td>\n",
       "      <td>2496999</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:2496880:2496999:+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2496880</td>\n",
       "      <td>2496999</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:2496880:2496999:+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2496880</td>\n",
       "      <td>2496999</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:2496880:2496999:+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2496880</td>\n",
       "      <td>2496999</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:2496880:2496999:+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "index    |    Chromosome    Start    End      Strand    ...\n",
       "int64    |    object        int64    int64    object    ...\n",
       "-------  ---  ------------  -------  -------  --------  -----\n",
       "252      |    chr1          999787   999865   -         ...\n",
       "343      |    chr1          1287596  1287672  +         ...\n",
       "362      |    chr1          1295826  1295889  -         ...\n",
       "362      |    chr1          1295826  1295889  -         ...\n",
       "...      |    ...           ...      ...      ...       ...\n",
       "972      |    chr1          2496880  2496999  +         ...\n",
       "972      |    chr1          2496880  2496999  +         ...\n",
       "972      |    chr1          2496880  2496999  +         ...\n",
       "972      |    chr1          2496880  2496999  +         ...\n",
       "PyRanges with 9 rows, 5 columns, and 1 index columns (with 4 index duplicates). (1 columns not shown: \"title\").\n",
       "Contains 1 chromosomes and 2 strands."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findExitrons(transformed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Iterate through each file. In each file, compare all its junctions to the ones in cds regions, find the contained junctions(exitrons), and add to final result matrix. Include score and person ID (what file it came from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Summarize junction info as list of unique junctions and their counts \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
