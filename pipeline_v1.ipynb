{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Pipeline for Detecting Exitrons (Exonic Introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm # progress tracker\n",
    "import pyranges as pr # parsing gff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse Regtools Data \n",
    "- Parse raw junction data from regtools output files\n",
    "\n",
    "- Processes 1 file at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJunctionFile(file_path):\n",
    "    # column names for RegTools junction files\n",
    "    regtools_column_names = [\n",
    "        'chrom', 'start_anchor', 'end_anchor', 'name', 'score', 'strand',\n",
    "        'thick_start_orig', 'thick_end_orig', 'item_rgb_orig',\n",
    "        'block_count_orig', 'block_sizes_orig', 'block_starts_orig'\n",
    "    ]\n",
    "    \n",
    "    # extract sample ID from the filename\n",
    "    sample_id = os.path.basename(file_path).split('.')[0]\n",
    "    \n",
    "    # read the file into a pandas DataFrame\n",
    "    df = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None, names=regtools_column_names,\n",
    "        dtype={'chrom': str, 'block_sizes_orig': str, 'block_starts_orig': str}\n",
    "    )\n",
    "        \n",
    "    df['sample_id_source'] = sample_id\n",
    "\n",
    "    # convert relevant columns to numeric types, coercing errors\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # drop rows if info is missing\n",
    "    df.dropna(subset=['start_anchor', 'end_anchor', 'score', 'block_sizes_orig'], inplace=True)\n",
    "    \n",
    "    # ensure int types\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Junction Data ** optimization needed **\n",
    "- Recalculates junction coordinates, following Regtools documentation to take into account blockSize\n",
    "\n",
    "- Recalculates block size to represent length of junction\n",
    "\n",
    "- Outputs junction info in BED12 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformJunctionData(raw_df):\n",
    "    \n",
    "    # CHROMOSOME FILTERING\n",
    "    original_row_count = len(raw_df)\n",
    "    \n",
    "    # allowed chromosomes\n",
    "    allowed_chrom_numbers = [str(i) for i in range(1, 23)]\n",
    "    allowed_sex_chroms_upper = ['X', 'Y'] \n",
    "    allowed_chromosomes = set()\n",
    "    for num_chrom in allowed_chrom_numbers:\n",
    "        allowed_chromosomes.add(num_chrom)\n",
    "        allowed_chromosomes.add(f\"chr{num_chrom}\")\n",
    "    for sex_chrom in allowed_sex_chroms_upper:\n",
    "        allowed_chromosomes.add(sex_chrom)\n",
    "        allowed_chromosomes.add(sex_chrom.lower())\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom}\")\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom.lower()}\")\n",
    "    \n",
    "    raw_df_filtered = raw_df[raw_df['chrom'].isin(allowed_chromosomes)].copy()\n",
    "    filtered_row_count = len(raw_df_filtered)\n",
    "    print(f\"Removed {original_row_count - filtered_row_count} rows with non-standard chromosomes.\")\n",
    "\n",
    "    # JUNCTION COORD CORRECTION\n",
    "    # initialize lists for each column\n",
    "    chrom_list = []\n",
    "    chromStart_list = []\n",
    "    chromEnd_list = []\n",
    "    name_list = []\n",
    "    score_list = []\n",
    "    strand_list = []\n",
    "    thickStart_list = []\n",
    "    thickEnd_list = []\n",
    "    itemRgb_list = []\n",
    "    blockCount_list = []\n",
    "    blockSizes_list = []\n",
    "    blockStarts_list = []\n",
    "    sample_id_source_list = []\n",
    "\n",
    "    # iterate over the filtered df (set to 1000 rows)\n",
    "    # realStart = \n",
    "\n",
    "    for i, (index, row) in enumerate(raw_df_filtered.iterrows()):\n",
    "\n",
    "        regtools_start = row['start_anchor']\n",
    "        regtools_end = row['end_anchor']\n",
    "        regtools_block_sizes_str = row['block_sizes_orig']\n",
    "\n",
    "        parsed_block_sizes = [int(s) for s in regtools_block_sizes_str.strip(',').split(',')]\n",
    "        if len(parsed_block_sizes) < 2:\n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "        \n",
    "        overhang_left = parsed_block_sizes[0]\n",
    "        overhang_right = parsed_block_sizes[1]\n",
    "\n",
    "        junc_start = regtools_start + overhang_left\n",
    "        junc_end = regtools_end - overhang_right\n",
    "\n",
    "        if junc_start >= junc_end: \n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "\n",
    "        junc_length = junc_end - junc_start\n",
    "\n",
    "        # add values to respective lists\n",
    "        chrom_list.append(row['chrom'])\n",
    "        chromStart_list.append(junc_start)\n",
    "        chromEnd_list.append(junc_end)\n",
    "        name_list.append(row['name'])\n",
    "        score_list.append(row['score'])\n",
    "        strand_list.append(row['strand'])\n",
    "        thickStart_list.append(junc_start)\n",
    "        thickEnd_list.append(junc_end)\n",
    "        itemRgb_list.append(row.get('item_rgb_orig', '0'))\n",
    "        blockCount_list.append(1)\n",
    "        blockSizes_list.append(str(junc_length))\n",
    "        blockStarts_list.append(\"0\")\n",
    "        sample_id_source_list.append(row['sample_id_source'])\n",
    "\n",
    "    # create df from dictionary of lists\n",
    "    transformed_df = pd.DataFrame({\n",
    "        'chrom': chrom_list,\n",
    "        'chromStart': chromStart_list,\n",
    "        'chromEnd': chromEnd_list,\n",
    "        'name': name_list,\n",
    "        'score': score_list,\n",
    "        'strand': strand_list,\n",
    "        'thickStart': thickStart_list,\n",
    "        'thickEnd': thickEnd_list,\n",
    "        'itemRgb': itemRgb_list,\n",
    "        'blockCount': blockCount_list,\n",
    "        'blockSizes': blockSizes_list,\n",
    "        'blockStarts': blockStarts_list,\n",
    "        'sample_id_source': sample_id_source_list\n",
    "    })\n",
    "    \n",
    "    print(f\"Transformed {len(transformed_df)} junction records.\")\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Exitrons Within Junction Data\n",
    "- Converts transformed junction data (transformed_df) and exon data (from gff3 file) into PyRanges objects with labels Chromosome, Start, End, Strand, and Title (a unique junction id formed by chrom:start:end:strand)\n",
    "\n",
    "- Finds junctions that overlap with CDS regions using PyRanges method .overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 903356 CDS regions.\n"
     ]
    }
   ],
   "source": [
    "# convert CDS data to PyRanges object\n",
    "gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "cds = gff[gff.Feature == \"CDS\"]\n",
    "print(f\"Found {len(cds)} CDS regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findExitrons(transformed_df):\n",
    "    # generate a unique ID for each junction (chrom:start:end:strand\n",
    "    unique_id = transformed_df['chrom'].astype(str) + ':' + \\\n",
    "                transformed_df['chromStart'].astype(str) + ':' + \\\n",
    "                transformed_df['chromEnd'].astype(str) + ':' + \\\n",
    "                transformed_df['strand'].astype(str)\n",
    "\n",
    "    # convert junction data to PyRanges object\n",
    "    junction_pr = pr.PyRanges({'Chromosome': transformed_df['chrom'],\n",
    "                    'Start': transformed_df['chromStart'],\n",
    "                    'End': transformed_df['chromEnd'],\n",
    "                    'Strand': transformed_df['strand'],\n",
    "                    'title': unique_id,\n",
    "                    'reads': transformed_df['score'],\n",
    "                    'sourceID': transformed_df['sample_id_source']}) \n",
    "\n",
    "    # find overlapping junctions\n",
    "    contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
    "    print(f\"Found {len(contained_junctions)} junctions contained within CDS regions.\")\n",
    "            \n",
    "    return contained_junctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile All Exitron Info\n",
    "- Iterates through each person's file, finding all exitron data then concatenating to a final matrix\n",
    "\n",
    "- Includes person ID (file name) and junction scores (total reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileExitronData(directory_path, file_pattern=\"*.bam.junc\"):\n",
    "\n",
    "    all_exitron_info = []\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "    print(f\"Found {len(file_paths)} files to process.\")\n",
    "\n",
    "    # testing first 5 out of 100\n",
    "    files_to_process = file_paths[:5]\n",
    "    print(f\"Processing the first {len(files_to_process)} files.\")\n",
    "\n",
    "    for file_path in tqdm(files_to_process):\n",
    "        print(\"Parsing new file...\")\n",
    "        file_name_only = os.path.basename(file_path)\n",
    "        try:\n",
    "            # 1.\n",
    "            parsed_data = parseJunctionFile(file_path)\n",
    "            # 2.\n",
    "            transformed_df = transformJunctionData(parsed_data)\n",
    "            # 3.\n",
    "            gr_file = findExitrons(transformed_df)\n",
    "            #4.\n",
    "            all_exitron_info.append(gr_file)\n",
    "\n",
    "        # skip to the next file if an error occurs\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing file {file_name_only}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue \n",
    "\n",
    "    # concatenate all individual data into matrix \n",
    "    final_gr = pr.concat(all_exitron_info)\n",
    "    print(f\"\\nSuccessfully compiled exitron data from {len(all_exitron_info)} files.\")\n",
    "    return final_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files to process.\n",
      "Processing the first 5 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing new file...\n",
      "Removed 405 rows with non-standard chromosomes.\n",
      "Transformed 225089 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1750773/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 20%|██        | 1/5 [00:48<03:14, 48.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5332 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 686 rows with non-standard chromosomes.\n",
      "Transformed 277524 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1750773/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 40%|████      | 2/5 [01:48<02:46, 55.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8193 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 523 rows with non-standard chromosomes.\n",
      "Transformed 283082 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1750773/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 60%|██████    | 3/5 [02:42<01:49, 54.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7228 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1009 rows with non-standard chromosomes.\n",
      "Transformed 301814 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1750773/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      " 80%|████████  | 4/5 [03:43<00:57, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9622 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 671 rows with non-standard chromosomes.\n",
      "Transformed 270306 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1750773/1365695747.py:18: UserWarning: overlap: 'auto' strand_behavior treated as ignore due to invalid Strand values. Please use strand_behavior=ignore\n",
      "  contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True)\n",
      "100%|██████████| 5/5 [04:35<00:00, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10160 junctions contained within CDS regions.\n",
      "\n",
      "Successfully concatenated exitron data from 5 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>title</th>\n",
       "      <th>reads</th>\n",
       "      <th>sourceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>chr1</td>\n",
       "      <td>999787</td>\n",
       "      <td>999865</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:999787:999865:-</td>\n",
       "      <td>2</td>\n",
       "      <td>CGND-HRA-00117-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1287596</td>\n",
       "      <td>1287672</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:1287596:1287672:+</td>\n",
       "      <td>3</td>\n",
       "      <td>CGND-HRA-00117-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1295826</td>\n",
       "      <td>1295889</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1295826:1295889:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00117-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1295826</td>\n",
       "      <td>1295889</td>\n",
       "      <td>-</td>\n",
       "      <td>chr1:1295826:1295889:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00117-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2029762</td>\n",
       "      <td>2029982</td>\n",
       "      <td>+</td>\n",
       "      <td>chr1:2029762:2029982:+</td>\n",
       "      <td>61</td>\n",
       "      <td>CGND-HRA-00117-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269443</th>\n",
       "      <td>chrY</td>\n",
       "      <td>13335800</td>\n",
       "      <td>13335891</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:13335800:13335891:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269646</th>\n",
       "      <td>chrY</td>\n",
       "      <td>19709578</td>\n",
       "      <td>19709689</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:19709578:19709689:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269646</th>\n",
       "      <td>chrY</td>\n",
       "      <td>19709578</td>\n",
       "      <td>19709689</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:19709578:19709689:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269646</th>\n",
       "      <td>chrY</td>\n",
       "      <td>19709578</td>\n",
       "      <td>19709689</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:19709578:19709689:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269646</th>\n",
       "      <td>chrY</td>\n",
       "      <td>19709578</td>\n",
       "      <td>19709689</td>\n",
       "      <td>-</td>\n",
       "      <td>chrY:19709578:19709689:-</td>\n",
       "      <td>1</td>\n",
       "      <td>CGND-HRA-00015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40535 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "index    |    Chromosome    Start     End       Strand    ...\n",
       "int64    |    object        int64     int64     object    ...\n",
       "-------  ---  ------------  --------  --------  --------  -----\n",
       "252      |    chr1          999787    999865    -         ...\n",
       "343      |    chr1          1287596   1287672   +         ...\n",
       "362      |    chr1          1295826   1295889   -         ...\n",
       "362      |    chr1          1295826   1295889   -         ...\n",
       "...      |    ...           ...       ...       ...       ...\n",
       "269646   |    chrY          19709578  19709689  -         ...\n",
       "269646   |    chrY          19709578  19709689  -         ...\n",
       "269646   |    chrY          19709578  19709689  -         ...\n",
       "269646   |    chrY          19709578  19709689  -         ...\n",
       "PyRanges with 40535 rows, 7 columns, and 1 index columns (with 28408 index duplicates). (3 columns not shown: \"title\", \"reads\", \"sourceID\").\n",
       "Contains 24 chromosomes and 3 strands (including non-genomic strands: ?)."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compileExitronData(\"/gpfs/commons/groups/knowles_lab/atokolyi/als/juncs_min6bp/\",file_pattern=\"*.bam.junc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Summarize Exitron Info \n",
    "- Lists all unique exitrons and their counts\n",
    "\n",
    "- Identifies which exitrons are already annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exitron Normalization\n",
    "- Divides exitron score by the reads of surrounding exons to find proportion of time that the exitron gets expressed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
