{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Pipeline for Detecting Exitrons (Exonic Introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/ncui/miniconda3/envs/vscode/lib/python3.13/site-packages/sorted_nearest/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm # progress tracker\n",
    "import pyranges as pr # parsing gff\n",
    "import numpy as np\n",
    "import pysam\n",
    "import itertools\n",
    "import pyranges as pr # parsing gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse Regtools Data \n",
    "- Parse raw junction data from regtools output files\n",
    "\n",
    "- Processes 1 file at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJunctionFile(file_path):\n",
    "    # column names for RegTools junction files\n",
    "    regtools_column_names = [\n",
    "        'chrom', 'start_anchor', 'end_anchor', 'name', 'score', 'strand',\n",
    "        'thick_start_orig', 'thick_end_orig', 'item_rgb_orig',\n",
    "        'block_count_orig', 'block_sizes_orig', 'block_starts_orig'\n",
    "    ]\n",
    "    \n",
    "    # extract sample ID from the filename\n",
    "    sample_id = os.path.basename(file_path).split('.')[0]\n",
    "    \n",
    "    # read the file into a pandas DataFrame\n",
    "    df = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None, names=regtools_column_names,\n",
    "        dtype={'chrom': str, 'block_sizes_orig': str, 'block_starts_orig': str}\n",
    "    )\n",
    "        \n",
    "    df['sample_id_source'] = sample_id\n",
    "\n",
    "    # convert relevant columns to numeric types, coercing errors\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # drop rows if info is missing\n",
    "    df.dropna(subset=['start_anchor', 'end_anchor', 'score', 'block_sizes_orig'], inplace=True)\n",
    "    \n",
    "    # ensure int types\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Junction Data\n",
    "- Recalculates junction coordinates, following Regtools documentation to take into account blockSize\n",
    "\n",
    "- Recalculates block size to represent length of junction\n",
    "\n",
    "- Outputs junction info in BED12 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformJunctionData(raw_df):\n",
    "    \n",
    "    # CHROMOSOME FILTERING\n",
    "    original_row_count = len(raw_df)\n",
    "    \n",
    "    # allowed chromosomes\n",
    "    allowed_chrom_numbers = [str(i) for i in range(1, 23)]\n",
    "    allowed_sex_chroms_upper = ['X', 'Y'] \n",
    "    allowed_chromosomes = set()\n",
    "    for num_chrom in allowed_chrom_numbers:\n",
    "        allowed_chromosomes.add(num_chrom)\n",
    "        allowed_chromosomes.add(f\"chr{num_chrom}\")\n",
    "    for sex_chrom in allowed_sex_chroms_upper:\n",
    "        allowed_chromosomes.add(sex_chrom)\n",
    "        allowed_chromosomes.add(sex_chrom.lower())\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom}\")\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom.lower()}\")\n",
    "    \n",
    "    raw_df_filtered = raw_df[raw_df['chrom'].isin(allowed_chromosomes)].copy()\n",
    "    filtered_row_count = len(raw_df_filtered)\n",
    "    print(f\"Removed {original_row_count - filtered_row_count} rows with non-standard chromosomes.\")\n",
    "\n",
    "\n",
    "    # JUNCTION COORD CORRECTION\n",
    "    # filter rows for valid blocks\n",
    "    parsed_blocks_list = raw_df_filtered['block_sizes_orig'].str.strip(',').str.split(',')\n",
    "    has_sufficient_blocks = parsed_blocks_list.str.len() >= 2\n",
    "    raw_df_filtered = raw_df_filtered[has_sufficient_blocks].copy()\n",
    "    parsed_blocks_list = parsed_blocks_list[has_sufficient_blocks]\n",
    "    \n",
    "    # recalculating junction coordinates\n",
    "    raw_df_filtered.loc[:, 'overhang_left'] = parsed_blocks_list.str[0].astype(int)\n",
    "    raw_df_filtered.loc[:, 'overhang_right'] = parsed_blocks_list.str[1].astype(int)\n",
    "\n",
    "    junc_start = raw_df_filtered['start_anchor'] + raw_df_filtered['overhang_left']\n",
    "    junc_end = raw_df_filtered['end_anchor'] - raw_df_filtered['overhang_right']\n",
    "\n",
    "    # filter out invalid junctions\n",
    "    valid_junction = junc_start < junc_end\n",
    "    raw_df_filtered = raw_df_filtered[valid_junction].copy()\n",
    "    junc_start = junc_start[valid_junction]\n",
    "    junc_end = junc_end[valid_junction]\n",
    "\n",
    "\n",
    "    junc_length = junc_end - junc_start\n",
    "\n",
    "    # create df\n",
    "    transformed_df = pd.DataFrame()\n",
    "    transformed_df['chrom'] = raw_df_filtered['chrom']\n",
    "    transformed_df['chromStart'] = junc_start\n",
    "    transformed_df['chromEnd'] = junc_end\n",
    "    transformed_df['name'] = raw_df_filtered['name']\n",
    "    transformed_df['score'] = raw_df_filtered['score']\n",
    "    transformed_df['strand'] = raw_df_filtered['strand']\n",
    "    transformed_df['thickStart'] = junc_start\n",
    "    transformed_df['thickEnd'] = junc_end\n",
    "    transformed_df['itemRgb'] = raw_df_filtered['item_rgb_orig']\n",
    "    transformed_df['blockCount'] = 1\n",
    "    transformed_df['blockSizes'] = junc_length.astype(str)\n",
    "    transformed_df['blockStarts'] = \"0\"\n",
    "    transformed_df['sample_id_source'] = raw_df_filtered['sample_id_source']\n",
    "\n",
    "    print(f\"Transformed {len(transformed_df)} junction records.\")\n",
    "    \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Exitrons Within Junction Data\n",
    "- Converts transformed junction data (transformed_df) and exon data (from gff3 file) into PyRanges objects with labels Chromosome, Start, End, Strand, and Title (a unique junction id formed by chrom:start:end:strand)\n",
    "\n",
    "- Finds junctions that overlap with CDS regions using PyRanges method .overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 903356 CDS regions.\n"
     ]
    }
   ],
   "source": [
    "# convert CDS data to PyRanges object\n",
    "gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "cds = gff[gff.Feature == \"CDS\"]\n",
    "print(f\"Found {len(cds)} CDS regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findExitrons(transformed_df):\n",
    "    transformed_df = transformed_df[transformed_df['strand'].isin(['+', '-'])]\n",
    "\n",
    "    # generate a unique ID for each junction (chrom:start:end:strand\n",
    "    unique_id = transformed_df['chrom'].astype(str) + ':' + \\\n",
    "                transformed_df['chromStart'].astype(str) + ':' + \\\n",
    "                transformed_df['chromEnd'].astype(str) + ':' + \\\n",
    "                transformed_df['strand'].astype(str)\n",
    "\n",
    "    # convert junction data to PyRanges object\n",
    "    junction_pr = pr.PyRanges({'Chromosome': transformed_df['chrom'],\n",
    "                    'Start': transformed_df['chromStart'],\n",
    "                    'End': transformed_df['chromEnd'],\n",
    "                    'Strand': transformed_df['strand'],\n",
    "                    'title': unique_id,\n",
    "                    'reads': transformed_df['score'],\n",
    "                    'sourceID': transformed_df['sample_id_source']}) \n",
    "\n",
    "    # find overlapping junctions\n",
    "    contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True, strand_behavior='same')\n",
    "    print(f\"Found {len(contained_junctions)} junctions contained within CDS regions.\")\n",
    "            \n",
    "    return contained_junctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile All Exitron Info\n",
    "- Iterates through each person's file, finding all exitron data then concatenating to a final matrix\n",
    "\n",
    "- Includes sourceID (file name) and junction scores (total reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileExitronData(directory_path, output_filepath, file_pattern=\"*.bam.junc\"):\n",
    "\n",
    "    all_exitron_info = []\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "    print(f\"Found {len(file_paths)} files to process.\")\n",
    "\n",
    "    # testing first 5 out of 100\n",
    "    '''\n",
    "    files_to_process = file_paths[:5]\n",
    "    print(f\"Processing the first {len(files_to_process)} files.\")\n",
    "    '''\n",
    "\n",
    "    for file_path in tqdm(file_paths):\n",
    "        print(\"Parsing new file...\")\n",
    "        file_name_only = os.path.basename(file_path)\n",
    "        try:\n",
    "            # 1.\n",
    "            parsed_data = parseJunctionFile(file_path)\n",
    "            # 2.\n",
    "            transformed_df = transformJunctionData(parsed_data)\n",
    "            # 3.\n",
    "            gr_file = findExitrons(transformed_df)\n",
    "            #4.\n",
    "            all_exitron_info.append(gr_file)\n",
    "\n",
    "        # skip to the next file if an error occurs\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing file {file_name_only}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue \n",
    "\n",
    "    # concatenate all individual data into matrix \n",
    "    final_gr = pr.concat(all_exitron_info)\n",
    "    print(f\"\\nSuccessfully compiled exitron data from {len(all_exitron_info)} files.\")\n",
    "    final_gr.to_parquet(output_filepath, index=False)\n",
    "    print(f\"Successfully saved data to {output_filepath}\")\n",
    "    return final_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compileExitronData(\"/gpfs/commons/groups/knowles_lab/atokolyi/als/juncs_min6bp/\", \"/gpfs/commons/home/ncui/project/final_exitron_data.parquet\", file_pattern=\"*.bam.junc\")\n",
    "# exitron data stored in final_exitron_data.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exitron Filtering\n",
    "- Returns wide dataframe of all unique exitrons with sourceIDs as columns and reads as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterExitronData(exitron_data_filepath, min_count=30, min_peeps=10):\n",
    "    long_df= pd.read_parquet(exitron_data_filepath)\n",
    "    # drop duplicates created by pyranges .overlap method\n",
    "    long_df.drop_duplicates(subset=['title', 'sourceID'], inplace=True)\n",
    "\n",
    "    # create filtered wide df\n",
    "    wide_df = long_df.pivot(index='title', columns='sourceID', values='reads').fillna(0)\n",
    "\n",
    "    wide_is_gt_count = wide_df > min_count\n",
    "    wide_is_gt_count_sums = wide_is_gt_count.sum(axis=1)\n",
    "    keep_juncs = wide_is_gt_count_sums[wide_is_gt_count_sums >= min_peeps].index\n",
    "    print(f\"Found {len(keep_juncs)} junctions that passed the filter.\")\n",
    "\n",
    "    # construct final matrix\n",
    "    filtered_exitron_data = wide_df.loc[keep_juncs].copy()\n",
    "    filtered_exitron_data = filtered_exitron_data.where(filtered_exitron_data >= min_count, 0)\n",
    "\n",
    "    return filtered_exitron_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_2513046/3035754114.py:7: PerformanceWarning: The following operation may generate 2610206368 cells in the resulting pandas object.\n",
      "  wide_df = long_df.pivot(index='title', columns='sourceID', values='reads').fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2797 junctions that passed the filter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sourceID</th>\n",
       "      <th>CGND-HRA-00013</th>\n",
       "      <th>CGND-HRA-00015</th>\n",
       "      <th>CGND-HRA-00017</th>\n",
       "      <th>CGND-HRA-00019</th>\n",
       "      <th>CGND-HRA-00020-2</th>\n",
       "      <th>CGND-HRA-00021</th>\n",
       "      <th>CGND-HRA-00023</th>\n",
       "      <th>CGND-HRA-00024</th>\n",
       "      <th>CGND-HRA-00025</th>\n",
       "      <th>CGND-HRA-00026</th>\n",
       "      <th>...</th>\n",
       "      <th>CGND-HRA-03135</th>\n",
       "      <th>CGND-HRA-03136</th>\n",
       "      <th>CGND-HRA-03137</th>\n",
       "      <th>CGND-HRA-03138</th>\n",
       "      <th>CGND-HRA-03139</th>\n",
       "      <th>CGND-HRA-03140</th>\n",
       "      <th>CGND-HRA-1927-1</th>\n",
       "      <th>CGND-HRA-1930-1</th>\n",
       "      <th>CGND-HRA-1941-1</th>\n",
       "      <th>CGND-HRA-1957-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr10:119042185:119042215:-</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042185:119042245:-</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042185:119042275:-</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042190:119042373:-</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042215:119042638:-</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sourceID                     CGND-HRA-00013  CGND-HRA-00015  CGND-HRA-00017  \\\n",
       "title                                                                         \n",
       "chr10:119042185:119042215:-             0.0             0.0             0.0   \n",
       "chr10:119042185:119042245:-             0.0             0.0             0.0   \n",
       "chr10:119042185:119042275:-             0.0             0.0             0.0   \n",
       "chr10:119042190:119042373:-             0.0             0.0             0.0   \n",
       "chr10:119042215:119042638:-             0.0             0.0             0.0   \n",
       "\n",
       "sourceID                     CGND-HRA-00019  CGND-HRA-00020-2  CGND-HRA-00021  \\\n",
       "title                                                                           \n",
       "chr10:119042185:119042215:-             0.0               0.0             0.0   \n",
       "chr10:119042185:119042245:-             0.0               0.0             0.0   \n",
       "chr10:119042185:119042275:-             0.0               0.0             0.0   \n",
       "chr10:119042190:119042373:-             0.0               0.0             0.0   \n",
       "chr10:119042215:119042638:-             0.0               0.0             0.0   \n",
       "\n",
       "sourceID                     CGND-HRA-00023  CGND-HRA-00024  CGND-HRA-00025  \\\n",
       "title                                                                         \n",
       "chr10:119042185:119042215:-             0.0             0.0             0.0   \n",
       "chr10:119042185:119042245:-             0.0             0.0             0.0   \n",
       "chr10:119042185:119042275:-             0.0             0.0             0.0   \n",
       "chr10:119042190:119042373:-             0.0             0.0             0.0   \n",
       "chr10:119042215:119042638:-             0.0             0.0             0.0   \n",
       "\n",
       "sourceID                     CGND-HRA-00026  ...  CGND-HRA-03135  \\\n",
       "title                                        ...                   \n",
       "chr10:119042185:119042215:-             0.0  ...             0.0   \n",
       "chr10:119042185:119042245:-             0.0  ...             0.0   \n",
       "chr10:119042185:119042275:-             0.0  ...             0.0   \n",
       "chr10:119042190:119042373:-             0.0  ...             0.0   \n",
       "chr10:119042215:119042638:-             0.0  ...             0.0   \n",
       "\n",
       "sourceID                     CGND-HRA-03136  CGND-HRA-03137  CGND-HRA-03138  \\\n",
       "title                                                                         \n",
       "chr10:119042185:119042215:-             0.0             0.0             0.0   \n",
       "chr10:119042185:119042245:-             0.0             0.0             0.0   \n",
       "chr10:119042185:119042275:-             0.0             0.0             0.0   \n",
       "chr10:119042190:119042373:-             0.0             0.0             0.0   \n",
       "chr10:119042215:119042638:-             0.0             0.0             0.0   \n",
       "\n",
       "sourceID                     CGND-HRA-03139  CGND-HRA-03140  CGND-HRA-1927-1  \\\n",
       "title                                                                          \n",
       "chr10:119042185:119042215:-             0.0             0.0              0.0   \n",
       "chr10:119042185:119042245:-             0.0           142.0              0.0   \n",
       "chr10:119042185:119042275:-             0.0             0.0              0.0   \n",
       "chr10:119042190:119042373:-             0.0             0.0              0.0   \n",
       "chr10:119042215:119042638:-             0.0             0.0              0.0   \n",
       "\n",
       "sourceID                     CGND-HRA-1930-1  CGND-HRA-1941-1  CGND-HRA-1957-1  \n",
       "title                                                                           \n",
       "chr10:119042185:119042215:-              0.0              0.0              0.0  \n",
       "chr10:119042185:119042245:-              0.0              0.0              0.0  \n",
       "chr10:119042185:119042275:-              0.0              0.0              0.0  \n",
       "chr10:119042190:119042373:-              0.0              0.0              0.0  \n",
       "chr10:119042215:119042638:-             30.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 1876 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter exitron data\n",
    "filtered_exitron_data = filterExitronData('final_exitron_data.parquet')\n",
    "filtered_exitron_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeExitronData(filtered_exitron_data, output_filepath):\n",
    "    annots = pd.DataFrame({\"exitron\": list(filtered_exitron_data.index)})\n",
    "    annots = pd.concat([annots, annots['exitron'].str.split(':', expand=True)], axis=1)\n",
    "    annots.columns = [\"exitron\", \"chr\", \"start\", \"end\", \"strand\"]\n",
    "    annots['start'] = annots['start'].astype(int)\n",
    "    annots['end'] = annots['end'].astype(int)\n",
    "\n",
    "    EXTEND = 6\n",
    "    normalized_df = np.zeros(filtered_exitron_data.shape)\n",
    "    ##tqdm(range(len(filtered_exitron_data.columns))):\n",
    "    for i in range(len(filtered_exitron_data.columns)):\n",
    "        print(\"Doing\",i)\n",
    "        source_id = filtered_exitron_data.columns[i]\n",
    "        bam_filepath = f'/gpfs/commons/projects/ALS_Consortium_resource/bam_files/{source_id}.bam'\n",
    "\n",
    "        with pysam.AlignmentFile(bam_filepath, 'rb') as bam:\n",
    "            for j in range(len(filtered_exitron_data.index)):\n",
    "                numerator = filtered_exitron_data.iat[j, i]\n",
    "\n",
    "                if numerator > 0:\n",
    "                    junc_chr = annots['chr'][j]\n",
    "                    junc_start = annots['start'][j]\n",
    "                    junc_end = annots['end'][j]\n",
    "\n",
    "                    # calculate denominator\n",
    "                    depth = bam.count_coverage(junc_chr, junc_start - EXTEND, junc_end + EXTEND, quality_threshold=0)\n",
    "                    totals = [sum(values) for values in zip(*depth)]\n",
    "                    \n",
    "                    denom = np.median(totals[:EXTEND] + totals[-EXTEND:])\n",
    "                    if denom > 0:\n",
    "                        normalized_df[j, i] = numerator / denom\n",
    "    np.save(output_filepath, normalized_df)\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1876 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "normalizeExitronData(filtered_exitron_data, 'normalized_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Idenitfying Novel vs Annotated Exitrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so starting an annotation matrix with our normalized junctions as rows, \n",
    "and then as columns whether the start matches the end of a known exon, \n",
    "and whether the end matches the start of a known exon. We can do this via \n",
    "set membership (i.e. junc_chr:junc_start in set of exon_chr:exon_end_pos)\n",
    "\n",
    "Note: Each tool/data (regtools, pysam, pyranges, gtf) seems to have its own \n",
    "coordinate system, depending on whether it is 0 or 1-based, or inclusive \n",
    "or exclusive. This will impact how we match the end/start of exons to the \n",
    "start/end of junctions. I.e. we may not be able to directly match the coordinate \n",
    "without first shifting +1 or -1 bp to the start or the end (which could differ). \n",
    "You'll need to figure out the basing of the tools and the adjustments \n",
    "necessary to compare between them. The lazy way that I would do this would be to \n",
    "compute how exon matches for junction starts and ends you get when you add -1,0,+1 \n",
    "to the start/end, and the one with the most matches is probably the correct shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "exons = gff[gff.Feature == \"exon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Source</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Score</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Frame</th>\n",
       "      <th>ID</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>...</th>\n",
       "      <th>exon_number</th>\n",
       "      <th>exon_id</th>\n",
       "      <th>transcript_support_level</th>\n",
       "      <th>havana_transcript</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>havana_gene</th>\n",
       "      <th>ont</th>\n",
       "      <th>protein_id</th>\n",
       "      <th>ccdsid</th>\n",
       "      <th>artif_dupl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>11120</td>\n",
       "      <td>11211</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>exon:ENST00000832824.1:1</td>\n",
       "      <td>ENSG00000290825.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSE00004248723.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>12009</td>\n",
       "      <td>12227</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>exon:ENST00000832824.1:2</td>\n",
       "      <td>ENSG00000290825.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSE00004248735.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>12612</td>\n",
       "      <td>12721</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>exon:ENST00000832824.1:3</td>\n",
       "      <td>ENSG00000290825.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>ENSE00003582793.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>13452</td>\n",
       "      <td>14413</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>exon:ENST00000832824.1:4</td>\n",
       "      <td>ENSG00000290825.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>ENSE00004248730.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>11124</td>\n",
       "      <td>11211</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>exon:ENST00000832825.1:1</td>\n",
       "      <td>ENSG00000290825.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSE00004248721.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  |    Chromosome    Source    Feature      Start      End  Score     ...\n",
       "  int64  |    object        object    object       int64    int64  object    ...\n",
       "-------  ---  ------------  --------  ---------  -------  -------  --------  -----\n",
       "      2  |    chr1          HAVANA    exon         11120    11211  .         ...\n",
       "      3  |    chr1          HAVANA    exon         12009    12227  .         ...\n",
       "      4  |    chr1          HAVANA    exon         12612    12721  .         ...\n",
       "      5  |    chr1          HAVANA    exon         13452    14413  .         ...\n",
       "      7  |    chr1          HAVANA    exon         11124    11211  .         ...\n",
       "PyRanges with 5 rows, 28 columns, and 1 index columns. (22 columns not shown: \"Strand\", \"Frame\", \"ID\", ...).\n",
       "Contains 1 chromosomes and 1 strands."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exons.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyExitrons(exitrons, exons):\n",
    "    split_coords = exitrons.index.str.split(':').tolist()\n",
    "    \n",
    "    junctions_long = pd.DataFrame(\n",
    "        split_coords,\n",
    "        columns=['Chromosome', 'Start', 'End', 'Strand'],\n",
    "        index=exitrons.index\n",
    "    )\n",
    "    junctions_long['Start'] = pd.to_numeric(junctions_long['Start'])\n",
    "    junctions_long['End'] = pd.to_numeric(junctions_long['End'])\n",
    "\n",
    "    # create sets of exon junction ends and starts\n",
    "    exon_starts_set = set(exons.Chromosome.astype(str) + ':' + exons.Start.astype(str))\n",
    "    exon_ends_set = set(exons.Chromosome.astype(str) + ':' + exons.End.astype(str))\n",
    "\n",
    "    # create the exitron keys for comparison \n",
    "    exitron_start_keys = junctions_long['Chromosome'].astype(str) + ':' + (junctions_long['Start']).astype(str)\n",
    "    exitron_end_keys = junctions_long['Chromosome'].astype(str) + ':' + (junctions_long['End']).astype(str)\n",
    "\n",
    "    # create the final boolean columns and add them to the original DataFrame\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            'start_match': exitron_start_keys.isin(exon_ends_set).values,\n",
    "            'end_match': exitron_end_keys.isin(exon_starts_set).values\n",
    "        },\n",
    "        index=exitrons.index\n",
    "    )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_match</th>\n",
       "      <th>end_match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr10:119042185:119042215:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042185:119042245:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042185:119042275:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042190:119042373:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr10:119042215:119042638:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:76428919:76429027:+</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:76428955:76429063:+</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:77683451:77683538:-</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:93672617:93672659:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:93672659:93672701:-</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             start_match  end_match\n",
       "title                                              \n",
       "chr10:119042185:119042215:-        False      False\n",
       "chr10:119042185:119042245:-        False      False\n",
       "chr10:119042185:119042275:-        False      False\n",
       "chr10:119042190:119042373:-        False      False\n",
       "chr10:119042215:119042638:-        False      False\n",
       "...                                  ...        ...\n",
       "chrX:76428919:76429027:+           False      False\n",
       "chrX:76428955:76429063:+           False      False\n",
       "chrX:77683451:77683538:-            True       True\n",
       "chrX:93672617:93672659:-           False      False\n",
       "chrX:93672659:93672701:-           False      False\n",
       "\n",
       "[2797 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identifyExitrons(filtered_exitron_data, exons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identifyExitrons(filtered_exitron_data, exons)['start_match'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(335)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identifyExitrons(filtered_exitron_data, exons)['end_match'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
