{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq Pipeline for Detecting Exitrons (Exonic Introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm # progress tracker\n",
    "import pyranges as pr # parsing gff\n",
    "import numpy as np\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse Regtools Data \n",
    "- Parse raw junction data from regtools output files\n",
    "\n",
    "- Processes 1 file at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseJunctionFile(file_path):\n",
    "    # column names for RegTools junction files\n",
    "    regtools_column_names = [\n",
    "        'chrom', 'start_anchor', 'end_anchor', 'name', 'score', 'strand',\n",
    "        'thick_start_orig', 'thick_end_orig', 'item_rgb_orig',\n",
    "        'block_count_orig', 'block_sizes_orig', 'block_starts_orig'\n",
    "    ]\n",
    "    \n",
    "    # extract sample ID from the filename\n",
    "    sample_id = os.path.basename(file_path).split('.')[0]\n",
    "    \n",
    "    # read the file into a pandas DataFrame\n",
    "    df = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None, names=regtools_column_names,\n",
    "        dtype={'chrom': str, 'block_sizes_orig': str, 'block_starts_orig': str}\n",
    "    )\n",
    "        \n",
    "    df['sample_id_source'] = sample_id\n",
    "\n",
    "    # convert relevant columns to numeric types, coercing errors\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # drop rows if info is missing\n",
    "    df.dropna(subset=['start_anchor', 'end_anchor', 'score', 'block_sizes_orig'], inplace=True)\n",
    "    \n",
    "    # ensure int types\n",
    "    for col in ['start_anchor', 'end_anchor', 'score']:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform Junction Data\n",
    "- Recalculates junction coordinates, following Regtools documentation to take into account blockSize\n",
    "\n",
    "- Recalculates block size to represent length of junction\n",
    "\n",
    "- Outputs junction info in BED12 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformJunctionData(raw_df):\n",
    "    \n",
    "    # CHROMOSOME FILTERING\n",
    "    original_row_count = len(raw_df)\n",
    "    \n",
    "    # allowed chromosomes\n",
    "    allowed_chrom_numbers = [str(i) for i in range(1, 23)]\n",
    "    allowed_sex_chroms_upper = ['X', 'Y'] \n",
    "    allowed_chromosomes = set()\n",
    "    for num_chrom in allowed_chrom_numbers:\n",
    "        allowed_chromosomes.add(num_chrom)\n",
    "        allowed_chromosomes.add(f\"chr{num_chrom}\")\n",
    "    for sex_chrom in allowed_sex_chroms_upper:\n",
    "        allowed_chromosomes.add(sex_chrom)\n",
    "        allowed_chromosomes.add(sex_chrom.lower())\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom}\")\n",
    "        allowed_chromosomes.add(f\"chr{sex_chrom.lower()}\")\n",
    "    \n",
    "    raw_df_filtered = raw_df[raw_df['chrom'].isin(allowed_chromosomes)].copy()\n",
    "    filtered_row_count = len(raw_df_filtered)\n",
    "    print(f\"Removed {original_row_count - filtered_row_count} rows with non-standard chromosomes.\")\n",
    "\n",
    "\n",
    "    # JUNCTION COORD CORRECTION\n",
    "    # filter rows for valid blocks\n",
    "    parsed_blocks_list = raw_df_filtered['block_sizes_orig'].str.strip(',').str.split(',')\n",
    "    has_sufficient_blocks = parsed_blocks_list.str.len() >= 2\n",
    "    raw_df_filtered = raw_df_filtered[has_sufficient_blocks].copy()\n",
    "    parsed_blocks_list = parsed_blocks_list[has_sufficient_blocks]\n",
    "    \n",
    "    # recalculating junction coordinates\n",
    "    raw_df_filtered.loc[:, 'overhang_left'] = parsed_blocks_list.str[0].astype(int)\n",
    "    raw_df_filtered.loc[:, 'overhang_right'] = parsed_blocks_list.str[1].astype(int)\n",
    "\n",
    "    junc_start = raw_df_filtered['start_anchor'] + raw_df_filtered['overhang_left']\n",
    "    junc_end = raw_df_filtered['end_anchor'] - raw_df_filtered['overhang_right']\n",
    "\n",
    "    # filter out invalid junctions\n",
    "    valid_junction = junc_start < junc_end\n",
    "    raw_df_filtered = raw_df_filtered[valid_junction].copy()\n",
    "    junc_start = junc_start[valid_junction]\n",
    "    junc_end = junc_end[valid_junction]\n",
    "\n",
    "\n",
    "    junc_length = junc_end - junc_start\n",
    "\n",
    "    # create df\n",
    "    transformed_df = pd.DataFrame()\n",
    "    transformed_df['chrom'] = raw_df_filtered['chrom']\n",
    "    transformed_df['chromStart'] = junc_start\n",
    "    transformed_df['chromEnd'] = junc_end\n",
    "    transformed_df['name'] = raw_df_filtered['name']\n",
    "    transformed_df['score'] = raw_df_filtered['score']\n",
    "    transformed_df['strand'] = raw_df_filtered['strand']\n",
    "    transformed_df['thickStart'] = junc_start\n",
    "    transformed_df['thickEnd'] = junc_end\n",
    "    transformed_df['itemRgb'] = raw_df_filtered['item_rgb_orig']\n",
    "    transformed_df['blockCount'] = 1\n",
    "    transformed_df['blockSizes'] = junc_length.astype(str)\n",
    "    transformed_df['blockStarts'] = \"0\"\n",
    "    transformed_df['sample_id_source'] = raw_df_filtered['sample_id_source']\n",
    "\n",
    "    print(f\"Transformed {len(transformed_df)} junction records.\")\n",
    "    \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Exitrons Within Junction Data\n",
    "- Converts transformed junction data (transformed_df) and exon data (from gff3 file) into PyRanges objects with labels Chromosome, Start, End, Strand, and Title (a unique junction id formed by chrom:start:end:strand)\n",
    "\n",
    "- Finds junctions that overlap with CDS regions using PyRanges method .overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 903356 CDS regions.\n"
     ]
    }
   ],
   "source": [
    "# convert CDS data to PyRanges object\n",
    "gff = pr.read_gff3(\"gencode.v48.annotation.gff3.gz\")\n",
    "cds = gff[gff.Feature == \"CDS\"]\n",
    "print(f\"Found {len(cds)} CDS regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findExitrons(transformed_df):\n",
    "    transformed_df = transformed_df[transformed_df['strand'].isin(['+', '-'])]\n",
    "\n",
    "    # generate a unique ID for each junction (chrom:start:end:strand\n",
    "    unique_id = transformed_df['chrom'].astype(str) + ':' + \\\n",
    "                transformed_df['chromStart'].astype(str) + ':' + \\\n",
    "                transformed_df['chromEnd'].astype(str) + ':' + \\\n",
    "                transformed_df['strand'].astype(str)\n",
    "\n",
    "    # convert junction data to PyRanges object\n",
    "    junction_pr = pr.PyRanges({'Chromosome': transformed_df['chrom'],\n",
    "                    'Start': transformed_df['chromStart'],\n",
    "                    'End': transformed_df['chromEnd'],\n",
    "                    'Strand': transformed_df['strand'],\n",
    "                    'title': unique_id,\n",
    "                    'reads': transformed_df['score'],\n",
    "                    'sourceID': transformed_df['sample_id_source']}) \n",
    "\n",
    "    # find overlapping junctions\n",
    "    contained_junctions = junction_pr.overlap(cds, contained_intervals_only=True, strand_behavior='same')\n",
    "    print(f\"Found {len(contained_junctions)} junctions contained within CDS regions.\")\n",
    "            \n",
    "    return contained_junctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile All Exitron Info\n",
    "- Iterates through each person's file, finding all exitron data then concatenating to a final matrix\n",
    "\n",
    "- Includes person ID (file name) and junction scores (total reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileExitronData(directory_path, output_filepath, file_pattern=\"*.bam.junc\"):\n",
    "\n",
    "    all_exitron_info = []\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "    print(f\"Found {len(file_paths)} files to process.\")\n",
    "\n",
    "    # testing first 5 out of 100\n",
    "    '''\n",
    "    files_to_process = file_paths[:5]\n",
    "    print(f\"Processing the first {len(files_to_process)} files.\")\n",
    "    '''\n",
    "\n",
    "    for file_path in tqdm(file_paths):\n",
    "        print(\"Parsing new file...\")\n",
    "        file_name_only = os.path.basename(file_path)\n",
    "        try:\n",
    "            # 1.\n",
    "            parsed_data = parseJunctionFile(file_path)\n",
    "            # 2.\n",
    "            transformed_df = transformJunctionData(parsed_data)\n",
    "            # 3.\n",
    "            gr_file = findExitrons(transformed_df)\n",
    "            #4.\n",
    "            all_exitron_info.append(gr_file)\n",
    "\n",
    "        # skip to the next file if an error occurs\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing file {file_name_only}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue \n",
    "\n",
    "    # concatenate all individual data into matrix \n",
    "    final_gr = pr.concat(all_exitron_info)\n",
    "    print(f\"\\nSuccessfully compiled exitron data from {len(all_exitron_info)} files.\")\n",
    "    final_gr.to_parquet(output_filepath, index=False)\n",
    "    print(f\"Successfully saved data to {output_filepath}\")\n",
    "    return final_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1876 files to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1876 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing new file...\n",
      "Removed 898 rows with non-standard chromosomes.\n",
      "Transformed 245111 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1876 [00:01<1:00:51,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7873 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1401 rows with non-standard chromosomes.\n",
      "Transformed 281682 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1876 [00:04<1:04:30,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10733 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 2779 rows with non-standard chromosomes.\n",
      "Transformed 311550 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1876 [00:06<1:07:58,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13517 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 903 rows with non-standard chromosomes.\n",
      "Transformed 274854 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1876 [00:08<1:07:46,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11393 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1158 rows with non-standard chromosomes.\n",
      "Transformed 303449 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1876 [00:11<1:11:04,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8532 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 797 rows with non-standard chromosomes.\n",
      "Transformed 272826 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1876 [00:13<1:10:10,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11530 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1401 rows with non-standard chromosomes.\n",
      "Transformed 429798 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1876 [00:16<1:19:16,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19533 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1689 rows with non-standard chromosomes.\n",
      "Transformed 274252 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1876 [00:18<1:15:48,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11662 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1071 rows with non-standard chromosomes.\n",
      "Transformed 286807 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/1876 [00:20<1:12:55,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13559 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 3154 rows with non-standard chromosomes.\n",
      "Transformed 277697 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1876 [00:22<1:10:45,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11014 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 518 rows with non-standard chromosomes.\n",
      "Transformed 242223 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1876 [00:24<1:07:12,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7248 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 716 rows with non-standard chromosomes.\n",
      "Transformed 259781 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1876 [00:26<1:05:34,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7208 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 681 rows with non-standard chromosomes.\n",
      "Transformed 293495 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1876 [00:28<1:06:13,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8172 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1329 rows with non-standard chromosomes.\n",
      "Transformed 287014 junction records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1876 [00:31<1:06:21,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12506 junctions contained within CDS regions.\n",
      "Parsing new file...\n",
      "Removed 1941 rows with non-standard chromosomes.\n"
     ]
    }
   ],
   "source": [
    "compileExitronData(\"/gpfs/commons/groups/knowles_lab/atokolyi/als/juncs_min6bp/\", \"/gpfs/commons/home/ncui/project/final_exitron_data.parquet\", file_pattern=\"*.bam.junc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Summarize Exitron Info \n",
    "- Lists all unique exitrons and their counts\n",
    "\n",
    "- Identifies which exitrons are already annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exitron Normalization\n",
    "- Divides exitron score by the reads of surrounding exons to find proportion of time that the exitron gets expressed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
